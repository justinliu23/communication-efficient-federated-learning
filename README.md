# communication-efficient-federated-learning
Quantization framework for reducing communication overhead in federated learning by converting client models from 32-bit floating-point to low-bit formats
